torch>=2.2.0
transformers>=4.40.0
sae-lens>=3.0.0
datasets>=2.18.0
huggingface_hub>=0.20.0
tqdm

# Optional: LLM-as-judge evaluation
# anthropic>=0.25.0  # Uncomment for Claude-based judge
# openai>=1.0.0       # Uncomment for OpenAI-based judge

# Optional: Flash Attention (for A100/H100)
# flash-attn>=2.5.0   # Install with: pip install flash-attn --no-build-isolation
